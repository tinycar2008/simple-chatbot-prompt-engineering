{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tinycar2008/simple-chatbot-prompt-engineering/blob/main/Assignment_13_LLM_task_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment 13 - LLM\n",
        "\n",
        "To demonstrate your familiarity with OpenAI API, build a tool that takes a technical question,\n",
        "and responds with an explanation. This is a tool that you will be able to use yourself during the course!"
      ],
      "metadata": {
        "id": "bWzo1CIgZG2E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Goal of my prompt engineering task\n",
        "\n",
        "The goal of this prompt engineering task:\n",
        "\n",
        "1. Creates a simple Chatbot\n",
        "2. Creates a simple Chatbot that can answer technical questions and respons with an explanation\n",
        "\n",
        "Credits to: https://medium.com/data-professor/beginners-guide-to-openai-api-a0420bc58ee5"
      ],
      "metadata": {
        "id": "jjI2TCCDiCeG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing libraries"
      ],
      "metadata": {
        "id": "tRUyYjoNkJkD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openai==0.28"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6X-C5eGt0XY",
        "outputId": "faa23ff4-5a59-4ae8-aee6-b2ef76f76b36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai==0.28 in /usr/local/lib/python3.10/dist-packages (0.28.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.67.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.11.10)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2024.12.14)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->openai==0.28) (4.12.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kYqUaHkAZDj9"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "from google.colab import userdata\n",
        "\n",
        "openai.api_key = userdata.get('OpenAIAssing13')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = 'gpt-4o-mini'"
      ],
      "metadata": {
        "id": "gq8BMbc1ktFN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Create simple chatbot to answer technical questions"
      ],
      "metadata": {
        "id": "5wQvrSY5kXMd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prompting to get relevant answers\n",
        "\n",
        "\"\n",
        "Your goal is to teach the datas science and prompt engineering and provide solutions and answers and ways to upskill\" \"My question is: What is batch normalisation\"\n",
        "\n",
        "\n",
        "\"\n",
        "Your goal is to teach the datas science and prompt engineering and provide solutions and answers and ways to upskill\" \"My question is: How do I generate a simple RNN model\""
      ],
      "metadata": {
        "id": "HbdGNcurpZtc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Type as a user \"Thank you for your help\" to stop chat with assistant to stop chat.**"
      ],
      "metadata": {
        "id": "Kqr6wyvqwmUV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "opening_prompt = \"Can I help you today with technical questions?\"\n",
        "expertise_prompt = \"\"\"\n",
        "You are a helpful and informative data science assistant.\n",
        "You are an expert in machine learning, deep learning, and data analysis.\n",
        "You are able to answer technical questions clearly and concisely.\n",
        "You can provide code examples in Python and R.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "W1z1Cik24zGl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the chat messages history\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": expertise_prompt},\n",
        "    {\"role\": \"system\", \"content\": opening_prompt}\n",
        "]"
      ],
      "metadata": {
        "id": "KwKfKTyRlY_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Function to display chat history\n",
        "\n",
        "def display_chat_history(messages):\n",
        "    for message in messages:\n",
        "      print(f\"{message['role'].capitalize()}: {message['content']}\")\n",
        "\n",
        "#Function to get assistants response\n",
        "\n",
        "def get_assistant_response(messages):\n",
        "  r = openai.ChatCompletion.create(\n",
        "      model=model,\n",
        "      messages=messages,\n",
        "      max_tokens=300\n",
        "  )\n",
        "  response = r.choices[0].message.content.strip()\n",
        "  return response\n",
        "\n",
        "#Main chat loop\n",
        "\n",
        "while True:\n",
        "\n",
        "  #Display chat history\n",
        "  display_chat_history(messages)\n",
        "\n",
        "  #Get user input\n",
        "  user_input = input(\"User: \")\n",
        "  messages.append({\"role\": \"user\", \"content\": user_input})\n",
        "\n",
        "  #Check if user wants to end conversation\n",
        "  if user_input.lower() == \"thank you for your help\":\n",
        "    print(\"Assistant: Goodbye! Have a great day!\")\n",
        "    break #exit the loop if the user says \"Thank you for your help\"\n",
        "\n",
        "  #Get assistant response\n",
        "  response = get_assistant_response(messages)\n",
        "  messages.append({\"role\": \"assistant\", \"content\": response})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDyeKCBGl799",
        "outputId": "8e71d7e7-46c9-496f-ee65-7966cb4238b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "System: \n",
            "You are a helpful and informative data science assistant. \n",
            "You are an expert in machine learning, deep learning, and data analysis.\n",
            "You are able to answer technical questions clearly and concisely.\n",
            "You can provide code examples in Python and R.\n",
            "\n",
            "System: Can I help you today with technical questions?\n",
            "User: Please explain what this code does and why: yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
            "System: \n",
            "You are a helpful and informative data science assistant. \n",
            "You are an expert in machine learning, deep learning, and data analysis.\n",
            "You are able to answer technical questions clearly and concisely.\n",
            "You can provide code examples in Python and R.\n",
            "\n",
            "System: Can I help you today with technical questions?\n",
            "User: Please explain what this code does and why: yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
            "Assistant: The line of code you provided is a Python expression that involves a generator function using `yield from` combined with a set comprehension. Let's break it down step-by-step to understand its components and overall purpose.\n",
            "\n",
            "### Breakdown of the Code\n",
            "\n",
            "1. **Set Comprehension**:\n",
            "   ```python\n",
            "   {book.get(\"author\") for book in books if book.get(\"author\")}\n",
            "   ```\n",
            "   - Here, we are iterating over a collection called `books`, which is presumably a list (or another iterable) of book dictionaries.\n",
            "   - For each `book` in `books`, the expression `book.get(\"author\")` is used to retrieve the value associated with the key `\"author\"`. \n",
            "   - The `if book.get(\"author\")` condition filters out any `book` where the `\"author\"` key is either missing or has a value that evaluates to `False` (like `None` or an empty string).\n",
            "   - The result of this set comprehension will be a set of authors (unique values) for all the books that have an \"author\" specified.\n",
            "\n",
            "2. **Yield from**:\n",
            "   ```python\n",
            "   yield from ...\n",
            "   ```\n",
            "   - The `yield from` expression is used in generator functions. It delegates the generation of values to another iterable (in this case, the set comprehension we discussed above).\n",
            "   - This means that each author in the set will be yielded one by one when the generator function is called.\n",
            "\n",
            "### Overall Purpose\n",
            "\n",
            "The\n",
            "User: Thank you for your help\n",
            "Assistant: Goodbye! Have a great day!\n"
          ]
        }
      ]
    }
  ]
}